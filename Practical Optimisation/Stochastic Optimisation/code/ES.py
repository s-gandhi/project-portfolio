import numpy as np
from numpy.linalg import norm


def f(x):
    """
    Function which evaluates the Rana-Function for an array of n-dimensional solutions.

    Parameters
    ----------
    x : (k, n) array
        Input array of k control variables, each of dimension n.

    Returns
    -------
    f_eval : (k, ) array
        Output array of k objective function values.

    """
    # Initialise the array of output values
    f_eval = np.zeros(x.shape[0])
    # Summation over (n-1) dimensions
    for i in range(x.shape[1] - 1):
        f_eval += x[:, i] * np.cos(np.sqrt(np.abs(x[:, i + 1] + x[:, i] + 1))) * np.sin(
            np.sqrt(np.abs(x[:, i + 1] - x[:, i] + 1))) + (1 + x[:, i + 1]) * np.cos(
            np.sqrt(np.abs(x[:, i + 1] - x[:, i] + 1))) * np.sin(np.sqrt(np.abs(x[:, i + 1] + x[:, i] + 1)))
    return f_eval


class ES:
    """
    Class for Evolutionary Strategy (ES) optimisation to find the minimum of an objective function f. An initial population x is generated by sampling from a uniform distribution over the feasible region. Parents are deterministically selected, and then mutated through a stochastic process. The mutated parents are recombined to form offspring. The objective function f is then evaluated for the newly formed offspring. The evolutionary cycle of selection, mutation and recombination repeats. The algorithm is terminated when the absolute difference in the objective function of the best and worst members of a parent population falls within a user-prescribed limit.
    """

    def __init__(self, f, n, bound, max_iter=10000, seed=0, mu=15, lambd=None, sel=',', epsilon=1, epsilon_s=0.05,
                 epsilon_c=1e-6, archive_size=25, d_min=None, d_sim=None, tau=None, tau_d=None, beta=None):
        """
        Class attribute initialisation.

        Attributes
        ----------
        f : func
            Objective function to be minimised.
        n : int
            Number of dimensions over which to optimise.
        bound : float
            Symmetric bound (+/-) on the domain of the control variables.
        max_iter : int, optional
            Maximum number of objective function evaluations. The default is 10000.
        seed : int, optional
            Random number generator seed for reproducibility. The default is 0.
        mu : int, optional
            Number of parents. The default is 15.
        lambd : int, optional
            Number of offspring. If lambd is None (default), the number of offspring is set to 7 * mu.
        sel : str, optional
            Selection scheme, either "," or "+". The default is ','
        epsilon : float, optional
            Termination threshold. The default is 1.
        epsilon_s : float, optional
            Lower limit on the standard deviation of the control variables. The default is 0.05
        epsilon_c : float, optional
            Positive constant by which to scale the identity matrix I added to the covariance matrix. Ensures the resulting matrix is PSD. The default is 1e-6.
        tau : float, optional
            Mutation control parameter. If tau is None (default), tau is set to 1 / sqrt(2 * sqrt(n)) (Schwefel [1977]).
        tau_d : float, optional
            Mutation control parameter. If tau is None (default), tau_d is set to 1 / sqrt(2 * n) (Schwefel [1977]).
        beta: float, optional
            Mutation control parameter. If beta is None (default), beta is set to 5 * pi / 180 (Schwefel [1977]).
        archive_size : int, optional
            Number of solutions to store in the archive. The default is 25.
        d_min : float, optional
            Archive dissimilarity threshold. If d_min is None (default), d_min is set to bound / 100.
        d_sim : float, optional
            Archive dissimilarity threshold. If d_sim is None (default), d_sim is set to d_min / 100.
        """
        # assertion check- selection scheme must be (mu,lambd) or (mu + lambd)
        assert sel in [',', '+'], "selection scheme must either be ',' or '+'"
        # initialise attributes
        self.f = f
        self.n = n
        self.bound = np.abs(bound)
        self.max_iter = max_iter
        self.seed = seed
        self.mu = mu
        if lambd:
            self.lambd = lambd
        else:
            self.lambd = 7 * self.mu
        self.sel = sel
        self.epsilon = epsilon
        self.epsilon_s = epsilon_s
        self.epsilon_c = epsilon_c
        self.archive_size = archive_size
        if d_min:
            self.d_min = d_min
        else:
            self.d_min = self.bound / 100
        if d_sim:
            self.d_sim = d_sim
        else:
            self.d_sim = self.d_min / 100
        if tau:
            self.tau = tau
        else:
            self.tau = 1 / np.sqrt(2 * np.sqrt(self.n))
        if tau_d:
            self.tau_d = tau_d
        else:
            self.tau_d = 1 / np.sqrt(2 * self.n)
        if beta:
            self.beta = beta
        else:
            self.beta = 5 * np.pi / 180

    def initialise(self):
        """
        Method which initialises the ES.

        Returns
        -------
        xp : (mu, n)
            Matrix of mu initial n-dimensional parent solutions.
        fp : (mu, )
            Vector of objective function values evaluated at the mu parent solutions.
        sigmap : (mu, n)
            Matrix of parent standard deviations.
        alphap : (mu, n)
            Matrix of parent rotation angles.
        iters : int
            Number of objective function evaluations.
        """
        # random seed for reproducibility
        np.random.seed(seed=self.seed)
        # generate the initial population by sampling from a multivariate uniform distribution over the feasible region
        xp = np.random.uniform(-self.bound, self.bound, [self.mu, self.n])
        # evaluate the objective function
        fxp = self.f(xp)
        # number of objective function evaluations
        iters = len(fxp)
        # initialise all standard deviations to 3
        sigmap = 3 * np.ones((self.mu, self.n))
        # initialise all rotation angles to 0
        alphap = np.zeros((self.mu, self.n, self.n))
        return xp, fxp, sigmap, alphap, iters

    def selection(self, xp, fxp, sigmap, alphap, xo, fxo, sigmao, alphao):
        """
        Method which performs selection. The best mu parents are selected from the pool of lambd offspring (, selection), or from the combined pool of previous mu parents and their lambd offspring (+ selection).

        Parameters
        ----------
        xp : (mu, n) array
            Matrix of mu previous parent solutions, each of dimension n.
        fxp : (mu, ) array
            Vector of function value evaluations for the mu previous parent solutions.
        sigmap : (mu, n) array
            Matrix of standard deviations for the previous parent solutions.
        alphap : (mu, n, n) array
            Matrix of rotation angles for the previous parent solutions.
        xo : (lambd, n) array
            Matrix of n-dimensional offspring solutions.
        fxo : (lambd, ) array
            Vector of function value evaluations for the lambd offspring solutions.
        sigmao : (lambd, n) array
            Matrix of standard deviations for the offpsring solutions.
        alphao : (lambd, n, n) array
            Matrix of rotation angles for the offspring solutions.

        Returns
        -------
        xp : (mu, n) array
            Matrix of mu parent solutions, each of dimension n.
        fxp : (mu, ) array
            Vector of function value evaluations for the mu parent solutions.
        sigmap : (mu, n) array
            Matrix of standard deviations for the parent solutions.
        alphap : (mu, n, n) array
            Matrix of rotation angles for the parent solutions.
        """
        if self.sel == ',':
            # select the mu lowest solutions from the offspring only
            idx = np.argsort(fxo)[:self.mu]
            xp = xo[idx]
            fxp = fxo[idx]
            sigmap = sigmao[idx]
            alphap = alphao[idx]
            return xp, fxp, sigmap, alphap
        else:
            # append the parents and offspring solutions to form a combined pool for selection
            xc = np.append(xo, xp, axis=0)
            fxc = np.append(fxo, fxp, axis=0)
            sigmac = np.append(sigmao, sigmap, axis=0)
            alphac = np.append(alphao, alphap, axis=0)
            # select the mu lowest solutions from the combined pool
            idx = np.argsort(fxc)[:self.mu]
            xp = xc[idx]
            fxp = fxc[idx]
            sigmap = sigmac[idx]
            alphap = alphac[idx]
            return xp, fxp, sigmap, alphap

    def mutation(self, x, sigma, alpha):
        """
        Method which performs mutation of the control variables and strategy parameters.

        Parameters
        ----------
        x : (mu, n) array
            Matrix of mu parent solutions, each of dimension n.
        sigma : (mu, n) array
            Matrix of parent standard deviations.
        alpha : (mu, n, n)
            Matrix of parent rotation angles.

        Returns
        -------
        xm : (mu, n) array
            Matrix of mu mutated solutions, each of dimension n.
        sigmam : (mu, n) array
            Matrix of mutated standard deviations.
        alpham : (mu, n, n)
            Matrix of mutated rotation angles.
        """
        # number of parents
        num_p = x.shape[0]
        # realisation of a N(0, 1) Gaussian, used in the mutation of all sigma values
        chi_0 = np.random.randn()
        # construct a (mu, n, n) matrix of random numbers drawn from N(0, 1) Gaussian distributions
        randn = np.random.randn(num_p, self.n, self.n)
        # construct a (mu, n, n) matrix of chi's from the realisation tmp
        # the upper triangular of tmp is taken
        # the lower triangular is constructed as the transpose of the upper triangular of tmp (excluding the leading diagional)
        # matrix is thus symmetric in axis 1 and 2 (chi_ij = chi_ji)
        chi = np.triu(randn) + np.transpose(np.triu(randn, 1), (0, 2, 1))
        # the (mu, n) matrix of chi_i's is taken as the diagonal elements of the (mu, n, n) matrix chi over axis 1 and 2
        chi_i = np.diagonal(chi, axis1=1, axis2=2)
        # mutate the standard deviations
        sigmam = sigma * np.exp(self.tau * chi_i + self.tau_d * chi_0)
        # mutate the rotation angles
        alpham = alpha + self.beta * chi
        # compute the off-diagonal elements of the (mu, n, n) mutated covariance matrix
        # the first bracketed term is a (mu, n, n) matrix of variance differences
        # of which the ij-th term is the difference (sigmam_i^2 - sigmam_j^2)
        # it is constructed by adding a new axis to each of the sigma matrices
        # such that they are (mu, n, 1) and transposing one matrix over axis 1 and 2
        # the second bracketed term is a (mu, n, n) matrix of two times the tangent of the mutated rotation angles
        # the two bracketed terms are multiplied element-wise to give the (mu, n, n) mutated covariance matrix
        covm = 0.5 * (sigmam[:, :, None] ** 2 - np.transpose(sigmam[:, :, None], (0, 2, 1)) ** 2) * np.tan(2 * alpham)
        # get the shape (mu, n, n) of the mutated covariance matrix
        s0, s1, s2 = covm.shape
        # set the diagonal elements over axis 1 and 2 of the (mu, n, n) mutated covaraince matrix to the mutated variances
        # a small term epsilon_c is added to ensure the mutated covariance matrix is PSD
        covm.reshape(s0, -1)[:, ::s2 + 1] = sigmam ** 2 + self.epsilon_c
        # draw a (mu, n) matrix of perturbations dx from Guassian distributions
        # dx[i] (n, ) is drawn from a N(0, covm[i]) distribution
        dx = np.array([np.random.multivariate_normal(mean=np.zeros(self.n), cov=covmi) for covmi in covm])
        # mutate the solution x by applying the perturbation dx
        xm = x + dx
        return xm, sigmam, alpham

    def discrete_recombination(self, xp, no):
        """
        Method which discretely recombines parent solutions to form a given number of offspring.

        Parameters
        ----------
        xp : (mu, n) array
            Matrix of mu parent solutions, each of dimension n.
        no : int
            Number of offspring to generate.

        Returns
        -------
        xo : (no, n) array
            Matrix of no offspring solutions, each of dimension n.
        """
        num_p = xp.shape[0]
        # randomly select parents 1 and 2 from the pool of potential parents
        x1 = xp[np.random.randint(low=0, high=num_p, size=no)]
        x2 = xp[np.random.randint(low=0, high=num_p, size=no)]
        # construct a binary mask for parent 1
        x1_mask = np.random.randint(low=0, high=2, size=np.array(x1.shape))
        # parent 2's mask is complementary to parent 1's
        x2_mask = np.logical_not(x1_mask)
        # recombine using masks to form offspring
        xo = x1_mask * x1 + x2_mask * x2
        return xo

    def intermediate_recombination(self, sigmap, alphap, no):
        """
        Method which intermediately recombines parent strategy parameters to form a given number of offspring strategy parameters.

        Parameters
        ----------
        sigmap : (mu, n) array
            Matrix of parent standard deviations.
        alphap : (mu, n, n) array
            Matrix of parent rotation angles.
        no : int
            Number of offspring to generate.

        Returns
        -------
        sigmap : (mu, n) array
            Matrix of offspring standard deviations.
        alphap : (mu, n, n) array
            Matrix of offspring rotation angles.
        """
        num_p = sigmap.shape[0]
        # randomly select parents 1 and 2 from the pool of potential parents
        idx1 = np.random.randint(low=0, high=num_p, size=no)
        idx2 = np.random.randint(low=0, high=num_p, size=no)

        sigma1 = sigmap[idx1]
        sigma2 = sigmap[idx2]
        # offspring standard deviation is formed as the arithmetic mean of the parent standard deviations
        sigmao = 0.5 * (sigma1 + sigma2)
        # force standard deviations to exceed a minimum value
        sigmao = np.where(sigmao > self.epsilon_s, sigmao, self.epsilon_s)
        # prevent standard deviations from exceeding a maximum value
        sigmao = np.where(sigmao < 100, sigmao, 100)

        alpha1 = alphap[idx1]
        alpha2 = alphap[idx2]
        # offspring rotation angles are formed as the arithmetic mean of the parent rotation angles
        alphao = 0.5 * (alpha1 + alpha2)
        # circularly map rotation angles which lie outside the range [-pi, pi] by adding/subtracting a factor of 2 * pi
        alphao = np.where(alphao < np.pi, alphao, alphao - 2 * np.pi)
        alphao = np.where(alphao > - np.pi, alphao, alphao + 2 * np.pi)
        return sigmao, alphao

    def update_archive(self, archive_x, archive_fx, x_j, f_j):
        """
        Method which updates the archive of best solutions.

        Parameters
        ----------
        archive_x : (k, n) array
            Matrix of k solutions, each of n dimensions, in the current archive.
        archive_fx : (k, ) array
            Vector of the objective function evaluated at the k solutions in the current archive.
        x_j : (n, ) array
            A new n-dimensional candidate solution for archiving.
        f_j : float
            Objective function evaluated at the candidate solution x_j.

        Returns
        -------
        archive_x : (l, n) array
            Matrix of k solutions, each of n dimensions, in the updated archive.
        archive_fx : (l, ) array
            Vector of the objective function evaluated at the l solutions in the updated archive.
        """
        # worst archived solution
        g_ind = np.argmax(archive_fx)
        f_g = archive_fx[g_ind]

        # Euclidean distance between new and archived solutions
        distance = norm(archive_x - x_j, axis=1)
        # archived solution x_e which most closely resembles new solution x_j (closest in Euclidean distance)
        e_ind = np.argmin(distance)
        d_ej = distance[e_ind]
        f_e = archive_fx[e_ind]

        # archive is not full
        if len(archive_x) < self.archive_size:
            # archive new solution x_j if it is sufficiently dissimilar to all the solutions archived
            if d_ej > self.d_min:
                archive_x.append(x_j)
                archive_fx.append(f_j)

        # archive is full
        else:
            # archive x_j if it is sufficiently dissimilar to all the solutions archived and better than the worst
            if d_ej > self.d_min and f_j < f_g:
                # new solution x_j replaces the worst archived solution x_g
                archive_x.pop(g_ind)
                archive_fx.pop(g_ind)
                archive_x.append(x_j)
                archive_fx.append(f_j)
            # archive x_j if it is not sufficiently dissimilar to all the solutions archived and better than the worst
            if d_ej < self.d_min and f_j < f_g:
                # new solution x_j replaces the closest archived solution x_e
                archive_x.pop(e_ind)
                archive_fx.pop(e_ind)
                archive_x.append(x_j)
                archive_fx.append(f_j)
            # archive x_j if it is not the best solution so far and sufficiently similar to but better than x_e
            if d_ej < self.d_sim and f_j < f_e:
                archive_x.pop(e_ind)
                archive_fx.pop(e_ind)
                archive_x.append(x_j)
                archive_fx.append(f_j)
        return archive_x, archive_fx

    def termination(self, fxp):
        """
        Method which tests the termination condition.

        Parameters
        ----------
        fxp : (mu, ) array
            Vector of objective function evaluations for mu parent solutions.

        Returns
        -------
        bool
            True if termination condition is met. False otherwise.
        """
        # test if absolute difference between worst and best solutions lies below the threshold epsilon
        return np.abs(max(fxp) - min(fxp)) < self.epsilon

    def run(self):
        """
        Method which runs the ES algorithm.

        Returns
        -------
        x_min : (n, ) array
            Minimised solution.
        fx_min : float
            Objective function evaluated at the minimised solution.
        archive_x : (k, n) array
            Matrix of k final archived solutions. Each control variable is of dimension n.
        archive_fx : (k, ) array
            Vector of objective function values evaluated at the k final archived solutions.
        """
        # generate initial solutions and control parameters
        xp, fxp, sigmap, alphap, iters = self.initialise()
        # form the initial archives from the initial solutions
        archive_x = [xp[0]]
        archive_fx = [fxp[0]]
        for i in range(xp.shape[0]):
            archive_x, archive_fx = self.update_archive(archive_x, archive_fx, xp[i], fxp[i])

        while iters < self.max_iter:
            if self.termination(fxp):
                break
            # initialise array of accepted offspring
            xo, sigmao, alphao = [], [], []
            # generate lambd valid offspring
            while len(xo) < self.lambd:
                no = self.lambd - len(xo)
                xm, sigmam, alpham = self.mutation(xp, sigmap, alphap)
                x_n = self.discrete_recombination(xm, no)
                sigma_n, alpha_n = self.intermediate_recombination(sigmam, alpham, no)
                # keep offspring solutions which adhere to inequality constraints
                idx = tuple([np.max(np.abs(x_n), axis=1) < self.bound])
                x_n, sigma_n, alpha_n = x_n[idx], sigma_n[idx], alpha_n[idx]
                # append valid offspring solutions to array of accepted offspring
                xo = np.append(xo, x_n).reshape(len(xo) + len(x_n), self.n)
                sigmao = np.append(sigmao, sigma_n).reshape(len(sigmao) + len(sigma_n), self.n)
                alphao = np.append(alphao, alpha_n).reshape(len(alphao) + len(alpha_n), self.n, self.n)

            fxo = self.f(xo)
            iters += self.lambd
            xp, fxp, sigmap, alphap = self.selection(xo, fxo, sigmao, alphao, xp, fxp, sigmap, alphap)

            # update archive with the parent solutions
            for i in range(xp.shape[0]):
                archive_x, archive_fx = self.update_archive(archive_x, archive_fx, xp[i], fxp[i])

        # best minimised solution
        idx = np.argmin(archive_fx)
        x_min = archive_x[idx]
        fx_min = archive_fx[idx]

        return x_min, fx_min, archive_x, archive_fx


def main():
    # number of dimensions and bound on feasible region
    n, bound = 5, 500
    es = ES(f, n, bound)
    x_min, fx_min, archive_x, archive_fx = es.run()


if __name__ == '__main__':
    main()
